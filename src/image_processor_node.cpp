#include <cuda_runtime.h>
#include <cv_bridge/cv_bridge.h>
#include <fstream>
#include <image_transport/image_transport.h>
#include <opencv4/opencv2/opencv.hpp>
#include <rocket_tracker/detectionMSG.h> // Autogenerated by ROS
#include <ros/package.h>
#include <ros/ros.h>

#include "NvInfer.h"

static ros::Publisher detectionPublisher;

static void **buffers;
nvinfer1::IExecutionContext *context;
static int32_t inputIndex = 0;
static int32_t outputIndex = 4;
static int64_t output_size = 1 * 25200 * 85; // default output size for YOLOv5
static int64_t input_size = 1 * 3 * 640 * 640;

static int num_classes = 80; // COCO class count
static int model_width = 640;
static int model_height = 640;

static cudaEvent_t start, stop;

static float *preprocessedFrame;
static int preprocessedFrameID = 0;
static ros::Time preprocessedFrameStamp;
static ros::Time preprocessedFrameArrivalStamp;
static ros::Time enqueuedFrameStamp;
static ros::Time enqueuedFrameArrivalStamp;
static int enqueuedFrameID;
static std::vector<float> gpu_output;
static bool newImagePreprocessed = false;

static std::string time_logging_string = "";
static bool TIME_LOGGING = false;
static bool TRACE_LOGGING = false;

template <typename... Args> std::string string_format(const std::string &format, Args... args) {
    // from https://stackoverflow.com/a/26221725
    int size_s = std::snprintf(nullptr, 0, format.c_str(), args...) + 1; // Extra space for '\0'
    if (size_s <= 0) {
        throw std::runtime_error("Error during formatting.");
    }
    auto size = static_cast<size_t>(size_s);
    auto buf = std::make_unique<char[]>(size);
    std::snprintf(buf.get(), size, format.c_str(), args...);
    return std::string(buf.get(), buf.get() + size - 1); // We don't want the '\0' inside
}

float *preprocessImgTRT(cv::Mat img) {
    // thanks to https://zhuanlan.zhihu.com/p/344810135
    if (img.empty()) {
        ROS_WARN("Empty image received!");
    }

    // only resize down
    if (img.rows > model_height || img.cols > model_width) {
        cv::resize(img, img, cv::Size(model_width, model_height));
    }

    static int model_size = model_width * model_height;
    static float *inputArray = new float[1 * 3 * model_size];

    // for each is significantly faster than all other methods to traverse over the cv::Mat (read
    // online and confirmed myself)
    img.forEach<cv::Vec3b>([](cv::Vec3b &p, const int *position) -> void {
        // p[0-2] contains bgr data, position[0-1] the row-column location
        // Incoming data is BGR, so convert to RGB in the process
        int index = model_height * position[0] + position[1];
        inputArray[index] = p[2] / 255.0f;
        inputArray[model_size + index] = p[1] / 255.0f;
        inputArray[2 * model_size + index] = p[0] / 255.0f;
    });

    return inputArray;
}

void postprocessTRTdetections(std::vector<float> cpu_output) {

    unsigned long dimensions =
        5 + num_classes; // 0,1,2,3 ->box,4->confidenceï¼Œ5-85 -> coco classes confidence
    unsigned long numPredictions = cpu_output.size() / dimensions; // 25.200
    unsigned long confidenceIndex = 4;
    unsigned long labelStartIndex = 5;

    if (TRACE_LOGGING) {
        std::string outputstring = "";
        for (int i = 0; i < 6; i++) {
            outputstring += std::to_string(cpu_output[i]) + " ";
            if (i == 3 || i == 4) {
                outputstring += "| ";
            }
        }
        ROS_INFO("%s", outputstring.c_str());
    }

    int highest_conf_index = 0;
    int highest_conf_label = 0;
    float highest_conf = 0.0f;
    for (unsigned long index = 0; index < output_size; index += dimensions) {
        float confidence = cpu_output[index + confidenceIndex];
        if (confidence <= 0.4f) {
            continue;
        }

        // for multiple classes, combine the confidence with class confidences
        // for single class models, this step can be skipped
        if (num_classes > 1) {
            for (unsigned long j = labelStartIndex; j < dimensions; ++j) {
                float combined_conf = cpu_output[index + j] * confidence;
                if (combined_conf > highest_conf) {
                    highest_conf = combined_conf;
                    highest_conf_index = index;
                    highest_conf_label = j;
                }
            }
        } else {
            if (confidence > highest_conf) {
                highest_conf = confidence;
                highest_conf_index = index;
                highest_conf_label = 6; // 5 + 1
            }
        }
    }

    rocket_tracker::detectionMSG detection;
    detection.frameID = enqueuedFrameID;
    detection.timestamp = ros::Time::now();
    detection.processingTime =
        (detection.timestamp.toNSec() - enqueuedFrameArrivalStamp.toNSec()) / 1000000.0;

    // Evaluate results
    if (highest_conf > 0.4f) {
        if (TRACE_LOGGING)
            ROS_INFO("Detected class %d with confidence %lf", highest_conf_label - 5, highest_conf);
        detection.propability = highest_conf;
        detection.classID = cpu_output[highest_conf_index + highest_conf_label];
        detection.centerX = cpu_output[highest_conf_index];
        detection.centerY = cpu_output[highest_conf_index + 1];
        detection.width = cpu_output[highest_conf_index + 2];
        detection.height = cpu_output[highest_conf_index + 3];
    }

    float gpu_time;
    cudaEventElapsedTime(&gpu_time, start, stop);
    float total_pipeline_time =
        (detection.timestamp.toNSec() - enqueuedFrameStamp.toNSec()) / 1000000.0f;
    if (TIME_LOGGING)
        ROS_INFO("Total frame processing time: %.2f (GPU: %.2f) Total Pipeline Time: %.2f",
                 detection.processingTime, gpu_time, total_pipeline_time);

    detectionPublisher.publish(detection);
}

void doGPUpass(float *inputArray) {
    // Execute everything that necessarily requires the GPU in one go
    // All on default Stream (0)
    cudaMemcpyAsync(buffers[inputIndex], inputArray, input_size * sizeof(float),
                    cudaMemcpyHostToDevice, 0);
    context->enqueueV2(buffers, 0, nullptr);
    cudaMemcpyAsync(gpu_output.data(), buffers[outputIndex], output_size * sizeof(float),
                    cudaMemcpyDeviceToHost, 0);
}

void callbackFrameGrabber(const sensor_msgs::ImageConstPtr &msg) {
    cv_bridge::CvImageConstPtr img = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);

    // check for missed frames
    static uint last_frame_id = msg->header.seq;
    if (msg->header.seq - last_frame_id > 1) {
        ROS_WARN("Frame dropped from FG->IP: jumped from index %u to %u", last_frame_id,
                 msg->header.seq);
    }
    last_frame_id = msg->header.seq;

    if (!img->image.empty()) {
        preprocessedFrameArrivalStamp = ros::Time::now();
        preprocessedFrame = preprocessImgTRT(img->image);
        preprocessedFrameID = msg->header.seq;
        preprocessedFrameStamp = msg->header.stamp;
        newImagePreprocessed = true;
    } else {
        ROS_WARN("Empty Frame received in image_processor_node::callbackFrameGrabber");
    }
}

void inferRandomMats(int iterations) {
    // Infers random matrices over n iterations

    rocket_tracker::detectionMSG detection;

    uint64_t pre = 0, fwd = 0, pst = 0;

    for (int i = 0; i < iterations; i++) {
        // create random matrix
        cv::Mat mat(model_width, model_height, CV_8UC3); // Or: Mat mat(2, 4, CV_64FC1);
        double mean = 0.0;
        double stddev = 500.0 / 3.0; // 99.7% of values will be inside [-500, +500] interval
        cv::randn(mat, cv::Scalar(0.0, 0.0, 0.0), cv::Scalar(255 / 3.0, 255 / 3.0, 255 / 3.0));

        uint64_t time1 = ros::Time::now().toNSec();
        // preprocessImgTRT(mat, buffers[inputIndex]);
        uint64_t time2 = ros::Time::now().toNSec();
        context->executeV2(buffers); // Invoke synchronous inference
        uint64_t time3 = ros::Time::now().toNSec();
        // postprocessTRTdetections(buffers[outputIndex], &detection);
        uint64_t time4 = ros::Time::now().toNSec();

        pre += time2 - time1;
        fwd += time3 - time2;
        pst += time4 - time3;
    }

    // Evaluate timings
    double total = (pre + fwd + pst) / 1000000.0;
    double avgtotal = (total / iterations);
    double avgpre = ((double)pre / iterations) / 1000000.0;
    double avgfwd = ((double)fwd / iterations) / 1000000.0;
    double avgpst = ((double)pst / iterations) / 1000000.0;
    ROS_INFO(
        "Performing inference for %d iterations took %.2lf ms. (Avg: %.2lf [%.2lf %.2lf %.2lf])",
        iterations, total, avgtotal, avgpre, avgfwd, avgpst);
}

void inferVideoInplace(std::string videopath, int iterations) {
    // Infers random matrices over n iterations

    // Open video file
    cv::VideoCapture capture;
    ROS_INFO("Infering video inplace from %s", videopath.c_str());
    capture = cv::VideoCapture(videopath);
    if (!capture.isOpened()) {
        capture.release();
        ROS_ERROR("Failed to open video capture! Provided path: %s", videopath.c_str());
        return;
    }
    cv::Mat videoFrame;
    rocket_tracker::detectionMSG detection;

    uint64_t pre = 0, fwd = 0, pst = 0;
    int detections = 0;

    for (int i = 0; i < iterations; i++) {
        // create random matrix
        if (!capture.read(videoFrame)) {
            capture.set(cv::CAP_PROP_POS_FRAMES, 0);
        }
        if (videoFrame.empty()) {
            continue;
        }

        uint64_t time1 = ros::Time::now().toNSec();
        // preprocessImgTRT(videoFrame, buffers[inputIndex]);
        uint64_t time2 = ros::Time::now().toNSec();
        context->executeV2(buffers); // Invoke synchronous inference
        uint64_t time3 = ros::Time::now().toNSec();
        // postprocessTRTdetections(buffers[outputIndex], &detection);
        uint64_t time4 = ros::Time::now().toNSec();

        if (detection.propability > 0.4)
            detections++;

        pre += time2 - time1;
        fwd += time3 - time2;
        pst += time4 - time3;
    }

    capture.release();

    // Evaluate timings
    double total = (pre + fwd + pst) / 1000000.0;
    double avgtotal = (total / iterations);
    double avgpre = ((double)pre / iterations) / 1000000.0;
    double avgfwd = ((double)fwd / iterations) / 1000000.0;
    double avgpst = ((double)pst / iterations) / 1000000.0;
    ROS_INFO("Performing inference for %d iterations took %.2lf ms, with %d items detected. (Avg: "
             "%.2lf [%.2lf %.2lf %.2lf])",
             iterations, total, detections, avgtotal, avgpre, avgfwd, avgpst);
}

class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char *msg) noexcept override {

        if (severity == Severity::kINFO) {
            ROS_INFO("[TensorRT] %s", msg);
        } else if (severity == Severity::kWARNING) {
            ROS_WARN("[TensorRT] %s", msg);
        } else if (severity == Severity::kERROR || severity == Severity::kINTERNAL_ERROR) {
            ROS_ERROR("[TensorRT] %s", msg);
        }
    }
} logger;

int main(int argc, char **argv) {

    ros::init(argc, argv, "IMAGEPROCESSOR");
    ros::NodeHandle nh("~");

    // Get weightfile path from arguments
    std::string weightfilepath;
    if (argc == 2) {
        weightfilepath = argv[1];
    } else {
        ROS_ERROR("Invalid number of argument passed to image processor.");
        ros::shutdown();
        return 0;
    }

    ros::param::get("/rocket_tracker/time_logging", TIME_LOGGING);
    ros::param::get("/rocket_tracker/trace_logging", TRACE_LOGGING);

    // TensorRT
    ROS_INFO("Initializing TRT");
    long size;
    char *trtModelStream;
    std::ifstream file(weightfilepath, std::ios::binary);
    ROS_INFO("Loading engine from %s", weightfilepath.c_str());
    if (file.good()) {
        file.seekg(0, file.end);
        size = file.tellg();
        file.seekg(0, file.beg);
        trtModelStream = new char[size];
        assert(trtModelStream);
        file.read(trtModelStream, size);
        file.close();
    }

    // Create runtime, deserialize engine and create execution context
    nvinfer1::IRuntime *runtime = nvinfer1::createInferRuntime(logger);
    assert(runtime != nullptr);
    nvinfer1::ICudaEngine *engine = runtime->deserializeCudaEngine(trtModelStream, size);
    assert(engine != nullptr);
    context = engine->createExecutionContext();
    assert(context != nullptr);
    delete[] trtModelStream;

    // Allocate memory for every engine binding, and gather input & output information
    inputIndex = engine->getBindingIndex("images");
    outputIndex = engine->getBindingIndex("output");
    ROS_INFO("Reading engine bindings:");
    buffers = new void *[engine->getNbBindings()];
    for (int i = 0; i < engine->getNbBindings(); i++) {

        std::string dimension_desc = " [";
        size_t size = 1;

        // Multiply every dimension of each binding to get its total size
        nvinfer1::Dims dims = engine->getBindingDimensions(i);
        for (size_t j = 0; j < dims.nbDims; ++j) {
            size *= dims.d[j];
            dimension_desc += std::to_string(dims.d[j]) + " ";
        }

        auto binding_size = size * 1 * sizeof(float);
        if (cudaMallocHost(&buffers[i], binding_size) != cudaSuccess) {
            ROS_WARN("Failed to allocate pinned memory! Switching to pageable memory instead.");
            if (cudaMalloc(&buffers[i], binding_size) != cudaSuccess) {
                ROS_ERROR("Could not allocate cuda memory.");
                return 0;
            }
        }

        dimension_desc.pop_back();
        dimension_desc += "] (\"" + std::string(engine->getBindingName(i)) + "\")";
        dimension_desc += " Datatype: " + std::to_string((int32_t)engine->getBindingDataType(i));

        if (i == outputIndex) {
            num_classes = dims.d[dims.nbDims - 1] - 5;
            output_size = size;
        } else if (i == inputIndex) {
            model_width = dims.d[dims.nbDims - 2];
            model_height = dims.d[dims.nbDims - 1];
            input_size = size;
        }

        ROS_INFO("%s", dimension_desc.c_str());
    }

    if (engine->getBindingDataType(inputIndex) != nvinfer1::DataType::kFLOAT ||
        engine->getBindingDataType(outputIndex) != nvinfer1::DataType::kFLOAT) {
        ROS_WARN("Engine input and/or output datatype is not float. Please change to a different "
                 "engine");
    }

    ROS_INFO("Loaded model with %d classes and input size %dx%d", num_classes, model_width,
             model_height);
    ros::param::set("/rocket_tracker/model_width", model_width);
    ros::param::set("/rocket_tracker/model_height", model_height);
    ros::param::set("/rocket_tracker/trt_ready", true);

    gpu_output.resize(output_size);

    ROS_INFO("TRT initialized");
    // ROS_INFO("Warming up over 200 iterations with random mats");
    // inferRandomMats(200);
    std::string videopath;

    int testiterations = 0;
    ros::param::get("/rocket_tracker/testiterations", testiterations);
    if (testiterations > 0) {
        ROS_INFO("Testing %d iterations inplace with video frames", testiterations);
        ros::param::param<std::string>("/rocket_tracker/videopath", videopath,
                                       "/home/david/Downloads/silent_launches.mp4");
        // inferVideoInplace(videopath, testiterations);
    }

    // Creating image-transport subscriber
    image_transport::ImageTransport it(nh);
    image_transport::Subscriber subimg = it.subscribe("/image_topic", 1, &callbackFrameGrabber);

    // Create ros publisher
    detectionPublisher = nh.advertise<rocket_tracker::detectionMSG>("/detection", 1);

    // Main loop
    ros::Rate r(150); // target fps
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    bool postProcessingFinished = true;
    while (ros::ok) {

        if (cudaStreamQuery(0) == cudaSuccess) {
            if (!postProcessingFinished) {
                postprocessTRTdetections(gpu_output); // only do this once
                postProcessingFinished = true;
            }

            // start next GPU pass if already possible
            if (newImagePreprocessed) {
                cudaEventRecord(start, 0);
                doGPUpass(preprocessedFrame);
                cudaEventRecord(stop, 0);
                newImagePreprocessed = false;
                postProcessingFinished = false;
                enqueuedFrameID = preprocessedFrameID;
                enqueuedFrameStamp = preprocessedFrameStamp;
                enqueuedFrameArrivalStamp = preprocessedFrameArrivalStamp;
            }
        }

        ros::spinOnce();
        r.sleep();
    }

    // Shut everything down cleanly
    for (int i = 0; i < engine->getNbBindings(); i++) {
        cudaFreeHost(buffers[i]);
    }
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    ros::shutdown();
    subimg.shutdown();
    detectionPublisher.shutdown();
    nh.shutdown();
    return 0;
}
