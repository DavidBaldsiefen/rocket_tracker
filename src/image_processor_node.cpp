#include <cv_bridge/cv_bridge.h>
#include <image_transport/image_transport.h>
#include <opencv4/opencv2/opencv.hpp>
#include <rocket_tracker/detectionMSG.h> // Autogenerated by ROS
#include <ros/package.h>
#include <ros/ros.h>
#include <torch/script.h>
#include <torch/torch.h>

static ros::Publisher detectionPublisher;

static torch::jit::script::Module module;
static torch::Device torchDevice = torch::Device(torch::kCPU);

bool init(std::string weightfilepath, bool usecuda) {

    if (torch::cuda::is_available() && usecuda) {
        torchDevice = torch::Device(torch::kCUDA);
        ROS_INFO("Using CUDA Device for YOLOv5");
        ros::param::set("/rocket_tracker/using_cuda", true);
    } else {
        torchDevice = torch::Device(torch::kCPU);
        ROS_INFO("Using CPU for YOLOv5");
        ros::param::set("/rocket_tracker/using_cuda", false);
    }

    try {
        // Deserialize the ScriptModule from a file using torch::jit::load().
        module = torch::jit::load(weightfilepath);
        module.to(torchDevice);
    } catch (const c10::Error &e) {
        ROS_ERROR("Could not load module from %s \n Error Messsage: %s", weightfilepath.c_str(),
                  e.msg().c_str());
        return false;
    }

    ROS_INFO("Model/weightfile loaded from %s", weightfilepath.c_str());
    return true;
}

rocket_tracker::detectionMSG processImage(cv::Mat img) {

    rocket_tracker::detectionMSG result;
    result.centerX = 0.0;
    result.centerY = 0.0;
    result.width = 0.0;
    result.height = 0.0;
    result.classID = 0;
    result.propability = 0.0;
    result.frameID = 0;

    // Preparing input tensor
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);

    uint64_t time = ros::Time::now().toNSec();

    torch::Tensor imgTensor =
        torch::from_blob(img.data, {img.rows, img.cols, img.channels()}, torch::kByte)
            .to(torchDevice);
    imgTensor = imgTensor.permute({2, 0, 1});
    imgTensor = imgTensor.toType(torch::kFloat);
    imgTensor = imgTensor.div(255);
    imgTensor = imgTensor.unsqueeze(0);

    uint64_t time2 = ros::Time::now().toNSec();

    torch::Tensor preds = module.forward({imgTensor}).toTuple()->elements()[0].toTensor();

    uint64_t time3 = ros::Time::now().toNSec();

    // Determine the tensor with the highest probability and take its parameters
    // we can actually completely skip "normal" nms because we only want to detect one object,
    // and will choose the highest propability one anyway
    if (preds.size(0) != 0) {

        torch::Tensor pred = preds.select(0, 0);
        torch::Tensor scores = pred.select(1, 4);

        // this if-check may not be necessary
        if (scores.sizes()[0] > 0) {

            // This is where the magic of getting the index (<1>) of the tensor with the highest
            // probability happens
            int maxTensorIndex = std::get<1>(torch::max(scores, 0)).item().toInt();
            torch::Tensor detection = pred[maxTensorIndex];

            if (detection[4].item().toDouble() > 0.5) {
                result.centerX = detection[0].item().toInt();
                result.centerY = detection[1].item().toInt();
                result.width = detection[2].item().toInt();
                result.height = detection[3].item().toInt();
                result.propability = detection[4].item().toDouble();
                result.classID = detection[5].item().toInt();
            }
        }
    }

    uint64_t time4 = ros::Time::now().toNSec();
    ROS_INFO("PRE: %.2lf FWD: %.2lf PST: %.2lf", (time2 - time) / 1000000.0,
             (time3 - time2) / 1000000.0, (time4 - time3) / 1000000.0);

    return result;
}

void callbackFrameGrabber(const sensor_msgs::ImageConstPtr &msg) {
    cv_bridge::CvImageConstPtr img = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);

    if (!img->image.empty()) {
        // TODO: sync frame_ids to detected coordinates
        rocket_tracker::detectionMSG detection;
        uint64_t time = ros::Time::now().toNSec();
        detection = processImage(img->image);
        detection.processingTime = (ros::Time::now().toNSec() - time) / 1000000.0;
        detection.timestamp = time / 1000000.0;
        detectionPublisher.publish(detection);
    } else {
        ROS_WARN("Empty Frame received in image_processor_node::callbackFrameGrabber");
    }
}

int main(int argc, char **argv) {

    ros::init(argc, argv, "FRAMEGRABBER");
    ros::NodeHandle nh("~");

    // Get weightfile path from arguments
    std::string weightfilepath;
    bool usecuda = true;
    if (argc == 2) {
        weightfilepath = argv[1];
    } else if (argc == 3) {
        weightfilepath = argv[1];
        std::string arg2(argv[2]);
        usecuda = !(arg2 == "false" || arg2 == "False" || arg2 == "0");
    } else {
        ROS_ERROR("No weightfile argument passed.");
        ros::shutdown();
        return 0;
    }

    if (!init(weightfilepath, usecuda)) {
        ros::shutdown();
        return 0;
    }

    // Creating image-transport subscriber
    image_transport::ImageTransport it(nh);
    image_transport::Subscriber subimg = it.subscribe("/image_topic", 1, &callbackFrameGrabber);

    // Create ros publisher
    detectionPublisher = nh.advertise<rocket_tracker::detectionMSG>("/detection", 1);

    // Main loop
    ros::spin();

    // Shut everything down cleanly
    ros::shutdown();
    subimg.shutdown();
    detectionPublisher.shutdown();
    nh.shutdown();
    return 0;
}
