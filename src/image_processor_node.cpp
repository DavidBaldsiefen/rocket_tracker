#include <cv_bridge/cv_bridge.h>
#include <image_transport/image_transport.h>
#include <opencv4/opencv2/cudaarithm.hpp>
#include <opencv4/opencv2/cudawarping.hpp>
#include <opencv4/opencv2/opencv.hpp>
#include <rocket_tracker/detectionMSG.h> // Autogenerated by ROS
#include <ros/package.h>
#include <ros/ros.h>
#include <torch/script.h>
#include <torch/torch.h>

#include "NvInfer.h"

static ros::Publisher detectionPublisher;

static torch::jit::script::Module module;
static torch::Device torchDevice = torch::Device(torch::kCPU);

const bool TIME_LOGGING = false;

bool init(std::string weightfilepath, bool usecuda) {

    if (torch::cuda::is_available() && usecuda) {
        torchDevice = torch::Device(torch::kCUDA);
        ROS_INFO("Using CUDA Device for YOLOv5");
        ros::param::set("/rocket_tracker/using_cuda", true);
    } else {
        torchDevice = torch::Device(torch::kCPU);
        ROS_INFO("Using CPU for YOLOv5");
        ros::param::set("/rocket_tracker/using_cuda", false);
    }

    try {
        // Deserialize the ScriptModule from a file using torch::jit::load().
        module = torch::jit::load(weightfilepath);
        module.to(torchDevice);
    } catch (const c10::Error &e) {
        ROS_ERROR("Could not load module from %s \n Error Messsage: %s", weightfilepath.c_str(),
                  e.msg().c_str());
        return false;
    }

    ROS_INFO("Model/weightfile loaded from %s", weightfilepath.c_str());
    return true;
}

std::vector<torch::Tensor> non_max_suppression(torch::Tensor preds, float score_thresh = 0.5,
                                               float iou_thresh = 0.5,
                                               torch::Device device = torch::Device(torch::kCPU)) {
    std::vector<torch::Tensor> output;
    for (size_t i = 0; i < preds.sizes()[0]; ++i) {
        torch::Tensor pred = preds.select(0, i);

        // Filter by scores
        torch::Tensor scores =
            pred.select(1, 4) * std::get<0>(torch::max(pred.slice(1, 5, pred.sizes()[1]), 1));
        pred = torch::index_select(pred, 0, torch::nonzero(scores > score_thresh).select(1, 0));
        if (pred.sizes()[0] == 0)
            continue;

        // (center_x, center_y, w, h) to (left, top, right, bottom)
        pred.select(1, 0) = pred.select(1, 0) - pred.select(1, 2) / 2;
        pred.select(1, 1) = pred.select(1, 1) - pred.select(1, 3) / 2;
        pred.select(1, 2) = pred.select(1, 0) + pred.select(1, 2);
        pred.select(1, 3) = pred.select(1, 1) + pred.select(1, 3);

        // Computing scores and classes
        std::tuple<torch::Tensor, torch::Tensor> max_tuple =
            torch::max(pred.slice(1, 5, pred.sizes()[1]), 1);
        pred.select(1, 4) = pred.select(1, 4) * std::get<0>(max_tuple);
        pred.select(1, 5) = std::get<1>(max_tuple);

        torch::Tensor dets = pred.slice(1, 0, 6);

        torch::Tensor keep = torch::empty({dets.sizes()[0]}, device);
        torch::Tensor areas =
            (dets.select(1, 3) - dets.select(1, 1)) * (dets.select(1, 2) - dets.select(1, 0));
        std::tuple<torch::Tensor, torch::Tensor> indexes_tuple =
            torch::sort(dets.select(1, 4), 0, 1);
        torch::Tensor v = std::get<0>(indexes_tuple);
        torch::Tensor indexes = std::get<1>(indexes_tuple);
        int count = 0;
        while (indexes.sizes()[0] > 0) {
            keep[count] = (indexes[0].item().toInt());
            count += 1;

            // Computing overlaps
            torch::Tensor lefts = torch::empty(indexes.sizes()[0] - 1, device);
            torch::Tensor tops = torch::empty(indexes.sizes()[0] - 1, device);
            torch::Tensor rights = torch::empty(indexes.sizes()[0] - 1, device);
            torch::Tensor bottoms = torch::empty(indexes.sizes()[0] - 1, device);
            torch::Tensor widths = torch::empty(indexes.sizes()[0] - 1, device);
            torch::Tensor heights = torch::empty(indexes.sizes()[0] - 1, device);
            for (size_t i = 0; i < indexes.sizes()[0] - 1; ++i) {
                lefts[i] = std::max(dets[indexes[0]][0].item().toFloat(),
                                    dets[indexes[i + 1]][0].item().toFloat());
                tops[i] = std::max(dets[indexes[0]][1].item().toFloat(),
                                   dets[indexes[i + 1]][1].item().toFloat());
                rights[i] = std::min(dets[indexes[0]][2].item().toFloat(),
                                     dets[indexes[i + 1]][2].item().toFloat());
                bottoms[i] = std::min(dets[indexes[0]][3].item().toFloat(),
                                      dets[indexes[i + 1]][3].item().toFloat());
                widths[i] =
                    std::max(float(0), rights[i].item().toFloat() - lefts[i].item().toFloat());
                heights[i] =
                    std::max(float(0), bottoms[i].item().toFloat() - tops[i].item().toFloat());
            }
            torch::Tensor overlaps = widths * heights;

            // FIlter by IOUs
            torch::Tensor ious =
                overlaps /
                (areas.select(0, indexes[0].item().toInt()) +
                 torch::index_select(areas, 0, indexes.slice(0, 1, indexes.sizes()[0])) - overlaps);
            indexes = torch::index_select(indexes, 0,
                                          torch::nonzero(ious <= iou_thresh).select(1, 0) + 1);
        }

        keep = keep.toType(torch::kInt64);
        output.push_back(torch::index_select(dets, 0, keep.slice(0, 0, count)));
    }
    return output;
}

rocket_tracker::detectionMSG processImage(cv::Mat img) {

    rocket_tracker::detectionMSG result;
    result.centerX = 0.0;
    result.centerY = 0.0;
    result.width = 0.0;
    result.height = 0.0;
    result.classID = 0;
    result.propability = 0.0;
    result.frameID = 0;

    // Preparing input tensor
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);

    uint64_t time = ros::Time::now().toNSec();

    torch::Tensor imgTensor =
        torch::from_blob(img.data, {img.rows, img.cols, img.channels()}, torch::kByte)
            .to(torchDevice);
    imgTensor = imgTensor.permute({2, 0, 1});
    imgTensor = imgTensor.toType(torch::kFloat);
    imgTensor = imgTensor.div(255);
    imgTensor = imgTensor.unsqueeze(0);

    uint64_t time2 = ros::Time::now().toNSec();

    torch::Tensor preds = module.forward({imgTensor}).toTuple()->elements()[0].toTensor();

    uint64_t time3 = ros::Time::now().toNSec();

    if (preds.size(0) != 0) {

        static bool use_highest_rocket = false;
        if (ros::param::getCached("rocket_tracker/use_highest_rocket", use_highest_rocket) &&
            use_highest_rocket) {
            // use NMS and determine highest rocket with probability > 0.5

            std::vector<torch::Tensor> dets = non_max_suppression(preds, 0.5, 0.5, torchDevice);
            if (dets.size() > 0) {
                int highestTarget = 0;
                int highestHeight =
                    10000; // height is counted top-to-bottom (coordinate system has 0 on top)

                for (int i = 0; i < dets[0].sizes()[0]; i++) {
                    int height = dets[0][i][1].item().toInt();
                    if (height < highestHeight) {
                        highestHeight = height;
                        highestTarget = i;
                    }
                }

                // Draw the highest scoring target
                int left = dets[0][highestTarget][0].item().toInt();   // * frame.cols / width;
                int top = dets[0][highestTarget][1].item().toInt();    // * frame.rows / height;
                int right = dets[0][highestTarget][2].item().toInt();  // * frame.cols / width;
                int bottom = dets[0][highestTarget][3].item().toInt(); // * frame.rows / height;
                result.centerX = left + (right - left) / 2;
                result.centerY = top + (bottom - top) / 2;
                result.width = (right - left);
                result.height = (bottom - top);
                result.classID = dets[0][highestTarget][5].item().toInt();
                result.propability = dets[0][highestTarget][4].item().toDouble();
            }

        } else {
            // Determine the tensor with the highest probability and take its parameters
            // we can actually completely skip "normal" nms because we only want to detect one
            // object, and will choose the highest propability one anyway no NMS necessary

            torch::Tensor pred = preds.select(0, 0);
            torch::Tensor scores = pred.select(1, 4);

            // this if-check may not be necessary
            if (scores.sizes()[0] > 0) {

                // This is where the magic of getting the index (<1>) of the tensor with the highest
                // probability happens
                int maxTensorIndex = std::get<1>(torch::max(scores, 0)).item().toInt();
                torch::Tensor detection = pred[maxTensorIndex];

                if (detection[4].item().toDouble() > 0.5) {
                    result.centerX = detection[0].item().toInt();
                    result.centerY = detection[1].item().toInt();
                    result.width = detection[2].item().toInt();
                    result.height = detection[3].item().toInt();
                    result.propability = detection[4].item().toDouble();
                    result.classID = detection[5].item().toInt();
                }
            }
        }
    }

    uint64_t time4 = ros::Time::now().toNSec();
    if (TIME_LOGGING)
        ROS_INFO("PRE: %.2lf FWD: %.2lf PST: %.2lf", (time2 - time) / 1000000.0,
                 (time3 - time2) / 1000000.0, (time4 - time3) / 1000000.0);

    return result;
}

void callbackFrameGrabber(const sensor_msgs::ImageConstPtr &msg) {
    cv_bridge::CvImageConstPtr img = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);

    // check for missed frames
    static uint last_frame_id = msg->header.seq;
    if (msg->header.seq - last_frame_id > 1) {
        ROS_WARN("Frame dropped from FG->IP: jumped from index %u to %u", last_frame_id,
                 msg->header.seq);
    }
    last_frame_id = msg->header.seq;

    if (!img->image.empty()) {
        // TODO: sync frame_ids to detected coordinates
        uint64_t time = ros::Time::now().toNSec();

        rocket_tracker::detectionMSG detection;
        detection = processImage(img->image);

        detection.processingTime = (ros::Time::now().toNSec() - time) / 1000000.0;
        detection.timestamp = time / 1000000.0;
        // total time between framecapture and detection being published:
        double detectionTime = (ros::Time::now().toNSec() - msg->header.stamp.toNSec()) / 1000000.0;
        if (TIME_LOGGING)
            ROS_INFO("Total detection time: %.2lf", detectionTime);

        detectionPublisher.publish(detection);
    } else {
        ROS_WARN("Empty Frame received in image_processor_node::callbackFrameGrabber");
    }
}

class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char *msg) noexcept override {
        // suppress info-level messages
        if (severity <= Severity::kWARNING) {
            ROS_INFO("[NvInfer] %s", msg);
        }
    }
} logger;

size_t getSizeByDim(const nvinfer1::Dims &dims) {
    size_t size = 1;
    for (size_t i = 0; i < dims.nbDims; ++i) {
        size *= dims.d[i];
    }
    return size;
}

void preprocessImage(const std::string &image_path, float *gpu_input, const nvinfer1::Dims &dims) {
    cv::Mat frame = cv::imread(image_path);
    if (frame.empty()) {
        std::cerr << "Input image " << image_path << " load failed\n";
        return;
    }
    cv::cuda::GpuMat gpu_frame;
    // upload image to GPU
    gpu_frame.upload(frame);
    auto input_width = dims.d[2];
    auto input_height = dims.d[1];
    auto channels = dims.d[0];
    auto input_size = cv::Size(input_width, input_height);
    // resize
    cv::cuda::GpuMat resized;
    cv::cuda::resize(gpu_frame, resized, input_size, 0, 0, cv::INTER_NEAREST);
    cv::cuda::GpuMat flt_image;
    resized.convertTo(flt_image, CV_32FC3, 1.f / 255.f);
    cv::cuda::subtract(flt_image, cv::Scalar(0.485f, 0.456f, 0.406f), flt_image, cv::noArray(), -1);
    cv::cuda::divide(flt_image, cv::Scalar(0.229f, 0.224f, 0.225f), flt_image, 1, -1);
    std::vector<cv::cuda::GpuMat> chw;
    for (size_t i = 0; i < channels; ++i) {
        chw.emplace_back(
            cv::cuda::GpuMat(input_size, CV_32FC1, gpu_input + i * input_width * input_height));
    }
    cv::cuda::split(flt_image, chw);
}

void doInference(nvinfer1::IExecutionContext &context, cudaStream_t &stream, void **buffers,
                 float *input, float *output, int batchSize) {
    // DMA input batch data to device, infer on the batch asynchronously, and DMA output back to
    // host
    ROS_INFO("calling cudaMemcpyAsync 1");
    cudaMemcpyAsync(buffers[0], input, batchSize * 3 * 640 * 640 * sizeof(float),
                    cudaMemcpyHostToDevice, stream);
    // CHECK(cudaMemcpyAsync(buffers[0], input, batchSize * 3 * 640 * 640 * sizeof(float),
    // cudaMemcpyHostToDevice, stream));
    ROS_INFO("calling enqueue");
    // context.enqueue(batchSize, buffers, stream, nullptr);
    context.enqueueV2(buffers, stream, nullptr);
    // OUTPUT_SIZE?
    ROS_INFO("calling cudaMemcpyAsync 2");
    cudaMemcpyAsync(output, buffers[1], batchSize * (7 * 7 * 30) * sizeof(float),
                    cudaMemcpyDeviceToHost, stream);
    // CHECK(cudaMemcpyAsync(output, buffers[1], batchSize * 1 * sizeof(float),
    // cudaMemcpyDeviceToHost, stream));
    ROS_INFO("calling cudaStreamSynchronize");
    cudaStreamSynchronize(stream);
    ROS_INFO("Leaving doInference");
}

struct YoloDetection {
    int classID;
    cv::Rect bbox;
};

void parseYolov5(cv::Mat &img, nvinfer1::ICudaEngine *engine, nvinfer1::IExecutionContext *context,
                 std::vector<YoloDetection> &batch_res) {
    // 准备数据 ---------------------------
    static float data[1 * 3 * 640 * 640]; //输入
    static float prob[1 * 7 * 7 * 30];    // Output-size  //输出

    ROS_INFO("Engine name: %s NbBindings: %d", engine->getName(), engine->getNbBindings());
    ROS_INFO("Name of Binding 0: %s", engine->getBindingName(0));
    ROS_INFO("Name of Binding 1: %s", engine->getBindingName(1));
    ROS_INFO("Name of Binding 2: %s", engine->getBindingName(2));
    ROS_INFO("Name of Binding 3: %s", engine->getBindingName(3));
    ROS_INFO("Name of Binding 4: %s", engine->getBindingName(4));
    // assert(engine->getNbBindings() == 2);

    void *buffers[2];
    // In order to bind the buffers, we need to know the names of the input and output tensors.
    // Note that indices are guaranteed to be less than IEngine::getNbBindings()
    const int inputIndex = engine->getBindingIndex("images");
    const int outputIndex = engine->getBindingIndex("output");
    assert(inputIndex == 0);
    // assert(outputIndex == 1);
    // Create GPU buffers on device
    cudaSetDevice(0);
    cudaError_t err = cudaMalloc(&buffers[0], 1 * 3 * 640 * 640 * sizeof(float));
    if (err != cudaSuccess)
        ROS_WARN("Unable to allocate memory! [%d]", err);

    err = cudaMalloc(&buffers[1], 1 * (7 * 7 * 30) * sizeof(float));
    if (err != cudaSuccess)
        ROS_WARN("Unable to allocate memory! [%d]", err);
    // CHECK(cudaMalloc(&buffers[0], 1 * 3 * 640 * 640 * sizeof(float)));
    // CHECK(cudaMalloc(&buffers[1], 1 * 1 * sizeof(float))); // OUTPUT_SIZE
    // Create stream
    cudaStream_t stream;
    cudaStreamCreate(&stream);
    // CHECK(cudaStreamCreate(&stream));

    if (!img.empty()) {
        cv::Mat pr_img;
        cv::cvtColor(img, pr_img, cv::COLOR_BGR2RGB);
        // cv::Mat pr_img = preprocess_img(img); // letterbox BGR to RGB
        int i = 0;
        for (int row = 0; row < 640; ++row) {
            uchar *uc_pixel = pr_img.data + row * pr_img.step;
            for (int col = 0; col < 640; ++col) {
                data[i] = (float)uc_pixel[2] / 255.0;
                data[i + 640 * 640] = (float)uc_pixel[1] / 255.0;
                data[i + 2 * 640 * 640] = (float)uc_pixel[0] / 255.0;
                uc_pixel += 3;
                ++i;
            }
        }
    }

    // Run inference
    doInference(*context, stream, buffers, data, prob, 1);

    // nms(batch_res, &prob[0 * 1], 0.5, 0.5); // OUTPUT_SIZE

    // Release stream and buffers
    cudaStreamDestroy(stream);
    cudaFree(buffers[0]);
    cudaFree(buffers[1]);
    // CHECK(cudaFree(buffers[0]));
    // CHECK(cudaFree(buffers[1]));
}

int main(int argc, char **argv) {

    ros::init(argc, argv, "FRAMEGRABBER");
    ros::NodeHandle nh("~");

    // Get weightfile path from arguments
    std::string weightfilepath;
    bool usecuda = true;
    if (argc == 2) {
        weightfilepath = argv[1];
    } else if (argc == 3) {
        weightfilepath = argv[1];
        std::string arg2(argv[2]);
        usecuda = !(arg2 == "false" || arg2 == "False" || arg2 == "0");
    } else {
        ROS_ERROR("No weightfile argument passed.");
        ros::shutdown();
        return 0;
    }

    if (!init(weightfilepath, usecuda)) {
        ros::shutdown();
        return 0;
    }

    // TensorRT
    ROS_INFO("Entering the danger zone");
    long size;
    char *trtModelStream;
    std::ifstream file("/home/david/NN-Models/yolov5/yolov5n.engine", std::ios::binary);
    if (file.good()) {
        file.seekg(0, file.end);
        size = file.tellg();
        file.seekg(0, file.beg);
        trtModelStream = new char[size];
        assert(trtModelStream);
        file.read(trtModelStream, size);
        file.close();
    }

    nvinfer1::IRuntime *runtime = nvinfer1::createInferRuntime(logger);
    assert(runtime != nullptr);
    nvinfer1::ICudaEngine *engine = runtime->deserializeCudaEngine(trtModelStream, size);
    assert(engine != nullptr);
    nvinfer1::IExecutionContext *context = engine->createExecutionContext();
    assert(context != nullptr);
    delete[] trtModelStream;

    cv::Mat frame = cv::imread("/home/david/Pictures/demo.jpg");
    std::vector<YoloDetection> detections;
    // parseYolov5(frame, engine, context, detections);

    ROS_INFO("Going into self-programmed stuff");

    // YOLOv5s has 5 Bindings
    ROS_INFO("Engine name: %s NbBindings: %d", engine->getName(), engine->getNbBindings());
    void *buffers[5];
    int32_t inputIndex = engine->getBindingIndex("images");
    int32_t outputIndex = engine->getBindingIndex("output");
    std::vector<nvinfer1::Dims> input_dims;  // we expect only one input
    std::vector<nvinfer1::Dims> output_dims; // and one output
    for (int i = 0; i < 5; i++) {
        ROS_INFO("Binding %d:\n[Name: %s][dType: %d]", i, engine->getBindingName(i),
                 int(engine->getBindingDataType(i)));

        auto binding_size = getSizeByDim(engine->getBindingDimensions(i)) * 1 * sizeof(float);

        cudaMalloc(&buffers[i], binding_size);

        if (i == inputIndex) {
            input_dims.emplace_back(engine->getBindingDimensions(i));
        } else if (i == outputIndex) {
            output_dims.emplace_back(engine->getBindingDimensions(i));
        }
    }

    // buffers[inputIndex] = inputBuffer;
    // buffers[outputIndex] = outputBuffer;

    // somehow put buffers on gpu, input image in buffer[inputIndex]

    // preprocessImage("/home/david/Pictures/demo.jpg", (float *)buffers[inputIndex],
    // input_dims[0]);
    cv::Mat inputImg = cv::imread("/home/david/Pictures/demo.jpg");
    if (frame.empty()) {
        std::cerr << "Input image load failed\n";
    }
    cv::resize(inputImg, inputImg, cv::Size(640, 640));
    cv::cvtColor(inputImg, inputImg, cv::COLOR_BGR2RGB);

    static float inputArray[1 * 3 * 640 * 640];
    int i = 0;
    for (int row = 0; row < 640; ++row) {
        uchar *uc_pixel = inputImg.data + row * inputImg.step;
        for (int col = 0; col < 640; ++col) {
            inputArray[i] = (float)uc_pixel[2] / 255.0;
            inputArray[i + 640 * 640] = (float)uc_pixel[1] / 255.0;
            inputArray[i + 2 * 640 * 640] = (float)uc_pixel[0] / 255.0;
            uc_pixel += 3;
            ++i;
        }
    }
    cudaMemcpy(buffers[0], inputArray, 1 * 3 * 640 * 640 * sizeof(float), cudaMemcpyHostToDevice);

    cudaStream_t stream;
    cudaStreamCreate(&stream);

    context->enqueueV2(buffers, stream, nullptr);

    // result is now in buffers[outputIndex]
    std::vector<float> cpu_output(getSizeByDim(output_dims[0]) * 1);
    cudaMemcpy(cpu_output.data(), buffers[outputIndex], cpu_output.size() * sizeof(float),
               cudaMemcpyDeviceToHost);
    ROS_INFO("Received output of size %ld", long(cpu_output.size())); // 2142000
    long numValuesOver4 = 0;
    long numValuesOver10 = 0;
    for (std::vector<float>::iterator it = cpu_output.begin(); it != cpu_output.end(); ++it) {
        //*it = *it / 1024.0; // "Conversion" to fp16
        if (*it > 0.4f) {
            numValuesOver4++;
            // ROS_INFO("%f", *it);
        }
        if (*it > 1.0f) {
            numValuesOver10++;
        }
    }
    ROS_INFO("Num values >.4: %ld | >1.0: %ld", numValuesOver4, numValuesOver10);

    // The Problem seems to be that the output is fp16 encoded, while "float" is fp32

    unsigned long outputSize = cpu_output.size();

    unsigned long dimensions = 85; // 0,1,2,3 ->box,4->confidence，5-85 -> coco classes confidence
    unsigned long rows = outputSize / dimensions; // 25.200
    unsigned long confidenceIndex = 4;
    unsigned long labelStartIndex = 5;
    float modelWidth = 640.0;
    float modelHeight = 640.0;
    float xGain = modelWidth / 640;
    float yGain = modelHeight / 640;

    std::vector<cv::Vec4f> locations;
    std::vector<int> labels;
    std::vector<float> confidences;

    std::vector<cv::Rect> src_rects;
    std::vector<cv::Rect> res_rects;
    std::vector<int> res_indexs;

    cv::Rect rect;
    cv::Vec4f location;
    long numPushbacks = 0;
    long long numSkips = 0;
    long long numSkips2 = 0;
    for (unsigned long i = 0; i < rows; ++i) {
        unsigned long index = i * dimensions;
        if (cpu_output[index + confidenceIndex] <= 0.4f) {
            numSkips++;
            continue;
        }

        for (unsigned long j = labelStartIndex; j < dimensions; ++j) {
            cpu_output[index + j] = cpu_output[index + j] * cpu_output[index + confidenceIndex];
        }

        for (unsigned long k = labelStartIndex; k < dimensions; ++k) {
            if (cpu_output[index + k] <= 0.5f) {
                numSkips2++;
                continue;
            }

            location[0] = (cpu_output[index] - cpu_output[index + 2] / 2) / xGain;     // top left x
            location[1] = (cpu_output[index + 1] - cpu_output[index + 3] / 2) / yGain; // top left y
            location[2] = (cpu_output[index] + cpu_output[index + 2] / 2) / xGain; // bottom right x
            location[3] =
                (cpu_output[index + 1] + cpu_output[index + 3] / 2) / yGain; // bottom right y

            locations.emplace_back(location);

            rect = cv::Rect(location[0], location[1], location[2] - location[0],
                            location[3] - location[1]);
            src_rects.push_back(rect);
            labels.emplace_back(k - labelStartIndex);

            confidences.emplace_back(cpu_output[index + k]);
            numPushbacks++;
        }
    }

    ROS_INFO("Confidences: %ld Rects: %ld Labels: %ld", confidences.size(), src_rects.size(),
             labels.size());
    ROS_INFO("Number of pushbacks: %ld Number of skips: (%lld %lld)", numPushbacks, numSkips,
             numSkips2);
    numValuesOver4 = 0;
    numValuesOver10 = 0;
    for (std::vector<float>::iterator it = confidences.begin(); it != confidences.end(); ++it) {
        if (*it > 0.4) {
            numValuesOver4++;
        }
        if (*it > 1.0) {
            numValuesOver10++;
        }
    }
    ROS_INFO("Num Confidences >.4: %ld | >1.0: %ld", numValuesOver4, numValuesOver10);

    // Evaluate results
    for (int i = 0; i < numValuesOver4; i++) {
        ROS_INFO("Label: %d Conf: %f", labels[i], confidences[i]);
    }

    cudaStreamDestroy(stream);
    for (void *buf : buffers) {
        cudaFree(buf);
    }

    ROS_INFO("Survived TRT stuff!");

    // Creating image-transport subscriber
    image_transport::ImageTransport it(nh);
    image_transport::Subscriber subimg = it.subscribe("/image_topic", 1, &callbackFrameGrabber);

    // Create ros publisher
    detectionPublisher = nh.advertise<rocket_tracker::detectionMSG>("/detection", 1);

    // Main loop
    ros::spin();

    // Shut everything down cleanly
    ros::shutdown();
    subimg.shutdown();
    detectionPublisher.shutdown();
    nh.shutdown();
    return 0;
}
