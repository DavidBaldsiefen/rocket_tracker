#include <cuda_runtime.h>
#include <cv_bridge/cv_bridge.h>
#include <fstream>
#include <image_transport/image_transport.h>
#include <opencv4/opencv2/opencv.hpp>
#include <rocket_tracker/detectionMSG.h> // Autogenerated by ROS
#include <ros/package.h>
#include <ros/ros.h>

#include "NvInfer.h"

static ros::Publisher detectionPublisher;

static void *buffers[5];
nvinfer1::IExecutionContext *context;
static int32_t inputIndex = 0;
static int32_t outputIndex = 4;

static int num_classes = 80; // COCO class count
static int model_width = 640;
static int model_height = 640;

const bool TIME_LOGGING = true;

void preprocessImgTRT(cv::Mat img, void *inputBuffer) {
    // inspired by https://zhuanlan.zhihu.com/p/344810135
    if (img.empty()) {
        ROS_WARN("Empty image received!");
    }

    uint64_t time = ros::Time::now().toNSec();

    cv::resize(img, img, cv::Size(model_width, model_height));
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);

    uint64_t time2 = ros::Time::now().toNSec();

    int model_size = model_width * model_height;
    float *inputArray = new float[1 * 3 * model_size];
    int i = 0;
    for (int row = 0; row < model_height; ++row) {
        uchar *uc_pixel = img.data + row * img.step;
        for (int col = 0; col < model_width; ++col) {
            inputArray[i] = (float)uc_pixel[2] / 255.0;
            inputArray[model_size + i] = (float)uc_pixel[1] / 255.0;
            inputArray[2 * model_size + i] = (float)uc_pixel[0] / 255.0;
            uc_pixel += 3;
            ++i;
        }
    }

    uint64_t time3 = ros::Time::now().toNSec();

    cudaMemcpy(inputBuffer, inputArray, 1 * 3 * model_width * model_height * sizeof(float),
               cudaMemcpyHostToDevice); // maybe I should free this every time?

    uint64_t time4 = ros::Time::now().toNSec();

    if (TIME_LOGGING)
        ROS_INFO("PRE: (CV: %.2lf ArrayPrep: %.2lf memcpy: %.2lf)", (time2 - time) / 1000000.0,
                 (time3 - time2) / 1000000.0, (time4 - time3) / 1000000.0);
}

void postprocessTRTdetections(void *outputBuffer, rocket_tracker::detectionMSG *detection) {

    // inspired by https://github.com/ultralytics/yolov5/issues/708#issuecomment-674422178

    uint64_t time = ros::Time::now().toNSec();

    std::vector<float> cpu_output(1 * 25200 * (5 + num_classes));

    cudaMemcpy(cpu_output.data(), outputBuffer, cpu_output.size() * sizeof(float),
               cudaMemcpyDeviceToHost); // this can be fastened by keeping stuff on gpu

    uint64_t time2 = ros::Time::now().toNSec();

    // The Problem seems to be that the output is fp16 encoded, while "float" is fp32

    unsigned long outputSize = cpu_output.size();

    unsigned long dimensions =
        5 + num_classes; // 0,1,2,3 ->box,4->confidenceï¼Œ5-85 -> coco classes confidence
    unsigned long rows = outputSize / dimensions; // 25.200
    unsigned long confidenceIndex = 4;
    unsigned long labelStartIndex = 5;

    std::vector<int> labels;
    std::vector<float> confidences;
    std::vector<cv::Rect> locations;

    cv::Rect rect;
    cv::Vec4f location;
    long numPushbacks = 0;
    long long numSkips = 0;
    long long numSkips2 = 0;
    for (unsigned long i = 0; i < rows; ++i) {
        unsigned long index = i * dimensions;
        if (cpu_output[index + confidenceIndex] <= 0.4f) {
            numSkips++;
            continue;
        }

        for (unsigned long j = labelStartIndex; j < dimensions; ++j) {
            cpu_output[index + j] = cpu_output[index + j] * cpu_output[index + confidenceIndex];
        }

        for (unsigned long k = labelStartIndex; k < dimensions; ++k) {
            if (cpu_output[index + k] <= 0.5f) {
                numSkips2++;
                continue;
            }

            // Model Output is [centerX, centerY, width, height] => rectangle based around center
            rect = cv::Rect(cpu_output[index], cpu_output[index + 1], cpu_output[index + 2],
                            cpu_output[index + 3]);
            locations.push_back(rect);

            labels.emplace_back(k - labelStartIndex);

            confidences.emplace_back(cpu_output[index + k]);
            numPushbacks++;
        }
    }

    uint64_t time3 = ros::Time::now().toNSec();

    // Evaluate results
    if (confidences.size() > 0) {
        float highest_conf = 0.0f;
        int highest_conf_index = 0;
        for (size_t i = 0; i < confidences.size(); i++) {
            if (confidences[i] > highest_conf) {
                highest_conf = confidences[i];
                highest_conf_index = i;
            }
        }
        detection->propability = highest_conf;
        detection->classID = labels[highest_conf_index];
        cv::Rect outRect = locations[highest_conf_index];
        detection->centerX = outRect.x;     // x1
        detection->centerY = outRect.y;     // y1
        detection->width = outRect.width;   // x2
        detection->height = outRect.height; // y2
    }

    uint64_t time4 = ros::Time::now().toNSec();

    if (TIME_LOGGING)
        ROS_INFO("POST: (MemCpy: %.2lf ToArrays: %.2lf Eval: %.2lf)", (time2 - time) / 1000000.0,
                 (time3 - time2) / 1000000.0, (time4 - time3) / 1000000.0);
}

rocket_tracker::detectionMSG processImage(cv::Mat img) {

    uint64_t time0 = ros::Time::now().toNSec();

    rocket_tracker::detectionMSG result;
    result.centerX = 0.0;
    result.centerY = 0.0;
    result.width = 0.0;
    result.height = 0.0;
    result.classID = 0;
    result.propability = 0.0;
    result.frameID = 0;

    uint64_t time = ros::Time::now().toNSec();

    // Prepare input tensor
    preprocessImgTRT(img, buffers[inputIndex]);

    uint64_t time2 = ros::Time::now().toNSec();

    context->executeV2(buffers); // Invoke synchronous inference

    uint64_t time3 = ros::Time::now().toNSec();

    postprocessTRTdetections(buffers[outputIndex], &result);

    uint64_t time4 = ros::Time::now().toNSec();
    if (TIME_LOGGING)
        ROS_INFO("PRE: %.2lf FWD: %.2lf PST: %.2lf TOTAL: %.2lf", (time2 - time) / 1000000.0,
                 (time3 - time2) / 1000000.0, (time4 - time3) / 1000000.0,
                 (time4 - time0) / 1000000.0);
    return result;
}

void callbackFrameGrabber(const sensor_msgs::ImageConstPtr &msg) {
    cv_bridge::CvImageConstPtr img = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);

    // check for missed frames
    static uint last_frame_id = msg->header.seq;
    if (msg->header.seq - last_frame_id > 1) {
        ROS_WARN("Frame dropped from FG->IP: jumped from index %u to %u", last_frame_id,
                 msg->header.seq);
    }
    last_frame_id = msg->header.seq;

    if (!img->image.empty()) {
        // TODO: sync frame_ids to detected coordinates
        uint64_t time = ros::Time::now().toNSec();

        rocket_tracker::detectionMSG detection;
        detection = processImage(img->image);

        detection.processingTime = (ros::Time::now().toNSec() - time) / 1000000.0;
        detection.timestamp = time / 1000000.0;
        // total time between framecapture and detection being published:
        double detectionTime = (ros::Time::now().toNSec() - msg->header.stamp.toNSec()) / 1000000.0;
        if (TIME_LOGGING)
            ROS_INFO("Total detection time: %.2lf", detectionTime);

        detectionPublisher.publish(detection);
    } else {
        ROS_WARN("Empty Frame received in image_processor_node::callbackFrameGrabber");
    }
}

class Logger : public nvinfer1::ILogger {
    void log(Severity severity, const char *msg) noexcept override {
        // suppress info-level messages
        if (severity <= Severity::kWARNING) {
            ROS_INFO("[NvInfer] %s", msg);
        }
    }
} logger;

int main(int argc, char **argv) {

    ros::init(argc, argv, "FRAMEGRABBER");
    ros::NodeHandle nh("~");

    // Get weightfile path from arguments
    std::string weightfilepath;
    bool usecuda = true;
    if (argc == 2) {
        weightfilepath = argv[1];
    } else if (argc == 3) {
        weightfilepath = argv[1];
        std::string arg2(argv[2]);
        usecuda = !(arg2 == "false" || arg2 == "False" || arg2 == "0");
    } else {
        ROS_ERROR("No weightfile argument passed.");
        ros::shutdown();
        return 0;
    }

    // TensorRT
    ROS_INFO("Initializing TRT");
    long size;
    char *trtModelStream;
    std::ifstream file(weightfilepath, std::ios::binary);
    if (file.good()) {
        file.seekg(0, file.end);
        size = file.tellg();
        file.seekg(0, file.beg);
        trtModelStream = new char[size];
        assert(trtModelStream);
        file.read(trtModelStream, size);
        file.close();
    }

    nvinfer1::IRuntime *runtime = nvinfer1::createInferRuntime(logger);
    assert(runtime != nullptr);
    nvinfer1::ICudaEngine *engine = runtime->deserializeCudaEngine(trtModelStream, size);
    assert(engine != nullptr);
    context = engine->createExecutionContext();
    assert(context != nullptr);
    delete[] trtModelStream;

    // Allocate memory for every engine binding
    inputIndex = engine->getBindingIndex("images");
    outputIndex = engine->getBindingIndex("output");
    ROS_INFO("Reading engine bindings:");
    for (int i = 0; i < 5; i++) {

        std::string dimension_desc = " [";
        size_t size = 1;

        // Multiply every dimension of each binding to get its total size
        nvinfer1::Dims dims = engine->getBindingDimensions(i);
        for (size_t j = 0; j < dims.nbDims; ++j) {
            size *= dims.d[j];
            dimension_desc += std::to_string(dims.d[j]) + " ";
        }

        auto binding_size = size * 1 * sizeof(float);
        cudaMalloc(&buffers[i], binding_size);

        dimension_desc.pop_back();
        dimension_desc += "] (\"" + std::string(engine->getBindingName(i)) + "\")";
        ROS_INFO("%s", dimension_desc.c_str());

        if (i == outputIndex) {
            num_classes = dims.d[dims.nbDims - 1] - 5;
        } else if (i == inputIndex) {
            model_width = dims.d[dims.nbDims - 2];
            model_height = dims.d[dims.nbDims - 1];
        }
    }

    ROS_INFO("Loaded model with %d classes and input size %dx%d", num_classes, model_width,
             model_height);
    ros::param::set("/rocket_tracker/model_width", model_width);
    ros::param::set("/rocket_tracker/model_height", model_height);
    ros::param::set("/rocket_tracker/trt_ready", true);

    ROS_INFO("TRT initialized");

    // Creating image-transport subscriber
    image_transport::ImageTransport it(nh);
    image_transport::Subscriber subimg = it.subscribe("/image_topic", 1, &callbackFrameGrabber);

    // Create ros publisher
    detectionPublisher = nh.advertise<rocket_tracker::detectionMSG>("/detection", 1);

    // Main loop
    ros::spin();

    // Shut everything down cleanly
    for (void *buf : buffers) {
        cudaFree(buf);
    }
    ros::shutdown();
    subimg.shutdown();
    detectionPublisher.shutdown();
    nh.shutdown();
    return 0;
}
